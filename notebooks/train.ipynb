{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b5b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from GNNs.GCNClassifier import GCNClassifier\n",
    "from GNNs.GRNClassifier import GRNClassifier\n",
    "\n",
    "from embeddings.word2vec import Word2VecEmbedding\n",
    "from embeddings.sbert import SBERTEmbedding\n",
    "\n",
    "from utils.graph_of_words import GraphOfWords\n",
    "from utils.graph_to_data import GraphToData\n",
    "from utils.dataset_wrapper import DatasetWrapper\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8dfdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "with open('../models/hateXplain/dataset.json', 'r', encoding='utf-8') as f:\n",
    "    raw_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7d9da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = np.load('../models/hateXplain/classes.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "063ca4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20148 samples.\n",
      "Text: i dont think im getting my baby them white 9 he has two white j and nikes not even touched\n",
      "Label: 1\n",
      "\n",
      "Text: we cannot continue calling ourselves feminists if the rights of all womxn arent addressed yes to a sexual offences public list but will a trans lesbian bisexual and queer womxn be able to enter their information on the reporting sheet gender forum\n",
      "Label: 1\n",
      "\n",
      "Text: nawt yall niggers ignoring me\n",
      "Label: 1\n",
      "\n",
      "Text: <user> i am bit confused coz chinese ppl can not access twitter thn how this ching chong using it i think he pakistani ðŸ¤” ðŸ¤” ðŸ¤”\n",
      "Label: 0\n",
      "\n",
      "Text: this bitch in whataburger eating a burger with no top bun and holding it palm up i hate white bitches\n",
      "Label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_majority_label(annotators):\n",
    "    labels = [a['label'] for a in annotators]\n",
    "    most_common = Counter(labels).most_common(1)\n",
    "    return most_common[0][0] if most_common else None\n",
    "\n",
    "texts, labels = [], []\n",
    "\n",
    "for post_id, post_data in raw_data.items():\n",
    "    majority_label = get_majority_label(post_data['annotators'])\n",
    "    if majority_label in encoder.classes_:\n",
    "        label_id = encoder.transform([majority_label])[0]\n",
    "        text = ' '.join(post_data['post_tokens'])\n",
    "        texts.append(text)\n",
    "        labels.append(label_id)\n",
    "\n",
    "print(f'Loaded {len(texts)} samples.')\n",
    "\n",
    "# Print the first 5 samples\n",
    "for i in range(5):\n",
    "    print(f'Text: {texts[i]}')\n",
    "    print(f'Label: {labels[i]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a62e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    test_texts, test_labels, test_size=0.5, random_state=42, stratify=test_labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2598ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_embedder = Word2VecEmbedding('../models/google/GoogleNews-vectors-negative300.kv', device=device)\n",
    "sbert_embedder = SBERTEmbedding(device=device)\n",
    "gow = GraphOfWords(embedding_model=sbert_embedder, window_size=2)\n",
    "text_to_graph = GraphToData(gow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cadf6096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_dataset = DatasetWrapper(train_texts, train_labels, text_to_graph)\n",
    "val_dataset = DatasetWrapper(val_texts, val_labels, text_to_graph)\n",
    "test_dataset = DatasetWrapper(test_texts, test_labels, text_to_graph)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78ff7696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 16118\n",
      "Unique labels in training set: {0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "\n",
    "for i, data in enumerate(train_dataset):\n",
    "    if data is None:\n",
    "        print(f\"Entry {i} is None\")\n",
    "\n",
    "\n",
    "all_labels = [data.y.item() for data in train_dataset]\n",
    "print(\"Unique labels in training set:\", set(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bb59805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Metrics ---\n",
      "Macro F1 Score: 0.5315\n",
      "Macro ROC AUC: 0.7517\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.66      0.62      0.64       624\n",
      "   offensive       0.55      0.84      0.67       815\n",
      "  hatespeech       0.61      0.19      0.29       576\n",
      "\n",
      "    accuracy                           0.59      2015\n",
      "   macro avg       0.61      0.55      0.53      2015\n",
      "weighted avg       0.60      0.59      0.55      2015\n",
      "\n",
      "Confusion Matrix:\n",
      "[[387 207  30]\n",
      " [ 88 686  41]\n",
      " [115 351 110]]\n",
      "Epoch 01 | Train Loss: 0.9843 | F1: 0.5315 | ROC-AUC: 0.7517\n",
      "=====================================\n",
      "\n",
      "--- Evaluation Metrics ---\n",
      "Macro F1 Score: 0.5759\n",
      "Macro ROC AUC: 0.7664\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.73      0.57      0.64       624\n",
      "   offensive       0.59      0.78      0.67       815\n",
      "  hatespeech       0.48      0.37      0.41       576\n",
      "\n",
      "    accuracy                           0.60      2015\n",
      "   macro avg       0.60      0.57      0.58      2015\n",
      "weighted avg       0.60      0.60      0.59      2015\n",
      "\n",
      "Confusion Matrix:\n",
      "[[357 162 105]\n",
      " [ 52 638 125]\n",
      " [ 82 283 211]]\n",
      "Epoch 02 | Train Loss: 0.8967 | F1: 0.5759 | ROC-AUC: 0.7664\n",
      "=====================================\n",
      "\n",
      "--- Evaluation Metrics ---\n",
      "Macro F1 Score: 0.5490\n",
      "Macro ROC AUC: 0.7708\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.75      0.55      0.63       624\n",
      "   offensive       0.54      0.88      0.67       815\n",
      "  hatespeech       0.57      0.24      0.34       576\n",
      "\n",
      "    accuracy                           0.59      2015\n",
      "   macro avg       0.62      0.56      0.55      2015\n",
      "weighted avg       0.62      0.59      0.57      2015\n",
      "\n",
      "Confusion Matrix:\n",
      "[[341 236  47]\n",
      " [ 39 715  61]\n",
      " [ 73 362 141]]\n",
      "Epoch 03 | Train Loss: 0.8734 | F1: 0.5490 | ROC-AUC: 0.7708\n",
      "=====================================\n",
      "\n",
      "--- Evaluation Metrics ---\n",
      "Macro F1 Score: 0.5953\n",
      "Macro ROC AUC: 0.7756\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.65      0.72      0.68       624\n",
      "   offensive       0.64      0.68      0.66       815\n",
      "  hatespeech       0.50      0.39      0.44       576\n",
      "\n",
      "    accuracy                           0.61      2015\n",
      "   macro avg       0.60      0.60      0.60      2015\n",
      "weighted avg       0.60      0.61      0.61      2015\n",
      "\n",
      "Confusion Matrix:\n",
      "[[450  88  86]\n",
      " [117 557 141]\n",
      " [128 221 227]]\n",
      "Epoch 04 | Train Loss: 0.8546 | F1: 0.5953 | ROC-AUC: 0.7756\n",
      "=====================================\n",
      "\n",
      "--- Evaluation Metrics ---\n",
      "Macro F1 Score: 0.5614\n",
      "Macro ROC AUC: 0.7797\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.79      0.54      0.64       624\n",
      "   offensive       0.55      0.86      0.67       815\n",
      "  hatespeech       0.53      0.29      0.37       576\n",
      "\n",
      "    accuracy                           0.60      2015\n",
      "   macro avg       0.62      0.56      0.56      2015\n",
      "weighted avg       0.62      0.60      0.58      2015\n",
      "\n",
      "Confusion Matrix:\n",
      "[[335 224  65]\n",
      " [ 29 703  83]\n",
      " [ 61 349 166]]\n",
      "Epoch 05 | Train Loss: 0.8406 | F1: 0.5614 | ROC-AUC: 0.7797\n",
      "=====================================\n",
      "\n",
      "--- Evaluation Metrics ---\n",
      "Macro F1 Score: 0.5931\n",
      "Macro ROC AUC: 0.7822\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.78      0.56      0.65       624\n",
      "   offensive       0.61      0.79      0.69       815\n",
      "  hatespeech       0.47      0.41      0.44       576\n",
      "\n",
      "    accuracy                           0.61      2015\n",
      "   macro avg       0.62      0.59      0.59      2015\n",
      "weighted avg       0.62      0.61      0.61      2015\n",
      "\n",
      "Confusion Matrix:\n",
      "[[349 143 132]\n",
      " [ 31 646 138]\n",
      " [ 70 268 238]]\n",
      "Epoch 06 | Train Loss: 0.8240 | F1: 0.5931 | ROC-AUC: 0.7822\n",
      "=====================================\n",
      "\n",
      "--- Evaluation Metrics ---\n",
      "Macro F1 Score: 0.5617\n",
      "Macro ROC AUC: 0.7839\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.65      0.74      0.69       624\n",
      "   offensive       0.59      0.81      0.68       815\n",
      "  hatespeech       0.66      0.20      0.31       576\n",
      "\n",
      "    accuracy                           0.62      2015\n",
      "   macro avg       0.63      0.59      0.56      2015\n",
      "weighted avg       0.63      0.62      0.58      2015\n",
      "\n",
      "Confusion Matrix:\n",
      "[[463 144  17]\n",
      " [109 664  42]\n",
      " [143 317 116]]\n",
      "Epoch 07 | Train Loss: 0.8084 | F1: 0.5617 | ROC-AUC: 0.7839\n",
      "=====================================\n",
      "\n",
      "--- Evaluation Metrics ---\n",
      "Macro F1 Score: 0.5768\n",
      "Macro ROC AUC: 0.7828\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.62      0.78      0.69       624\n",
      "   offensive       0.63      0.73      0.68       815\n",
      "  hatespeech       0.56      0.27      0.37       576\n",
      "\n",
      "    accuracy                           0.61      2015\n",
      "   macro avg       0.60      0.59      0.58      2015\n",
      "weighted avg       0.61      0.61      0.59      2015\n",
      "\n",
      "Confusion Matrix:\n",
      "[[485  97  42]\n",
      " [137 598  80]\n",
      " [166 254 156]]\n",
      "Epoch 08 | Train Loss: 0.7911 | F1: 0.5768 | ROC-AUC: 0.7828\n",
      "=====================================\n",
      "\n",
      "--- Evaluation Metrics ---\n",
      "Macro F1 Score: 0.5790\n",
      "Macro ROC AUC: 0.7846\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.76      0.61      0.67       624\n",
      "   offensive       0.57      0.87      0.69       815\n",
      "  hatespeech       0.58      0.28      0.37       576\n",
      "\n",
      "    accuracy                           0.62      2015\n",
      "   macro avg       0.64      0.58      0.58      2015\n",
      "weighted avg       0.63      0.62      0.59      2015\n",
      "\n",
      "Confusion Matrix:\n",
      "[[380 196  48]\n",
      " [ 40 707  68]\n",
      " [ 83 334 159]]\n",
      "Epoch 09 | Train Loss: 0.7745 | F1: 0.5790 | ROC-AUC: 0.7846\n",
      "=====================================\n",
      "\n",
      "--- Evaluation Metrics ---\n",
      "Macro F1 Score: 0.5818\n",
      "Macro ROC AUC: 0.7861\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.70      0.71      0.71       624\n",
      "   offensive       0.60      0.83      0.70       815\n",
      "  hatespeech       0.55      0.25      0.34       576\n",
      "\n",
      "    accuracy                           0.63      2015\n",
      "   macro avg       0.62      0.60      0.58      2015\n",
      "weighted avg       0.62      0.63      0.60      2015\n",
      "\n",
      "Confusion Matrix:\n",
      "[[443 135  46]\n",
      " [ 70 674  71]\n",
      " [119 313 144]]\n",
      "Epoch 10 | Train Loss: 0.7585 | F1: 0.5818 | ROC-AUC: 0.7861\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "def train(model, loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device, label_names=None):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)  # logits\n",
    "            probs = torch.softmax(out, dim=1)\n",
    "            preds = out.argmax(dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(data.y.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    y_true = np.array(all_targets)\n",
    "    y_pred = np.array(all_preds)\n",
    "    y_probs = np.array(all_probs)\n",
    "\n",
    "    # Global metrics\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, y_probs, multi_class='ovr', average='macro')\n",
    "    except ValueError:\n",
    "        roc_auc = float('nan')\n",
    "\n",
    "    # Per-class metrics\n",
    "    precision, recall, f1s, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, zero_division=0\n",
    "    )\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(\"\\n--- Evaluation Metrics ---\")\n",
    "    print(f\"Macro F1 Score: {f1:.4f}\")\n",
    "    print(f\"Macro ROC AUC: {roc_auc:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=label_names or [str(i) for i in range(len(precision))]))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    return f1, roc_auc\n",
    "\n",
    "model = GCNClassifier(in_channels=384, hidden_channels=128, num_classes=3).to(device) # Adjust input size when changing embedder!!!!\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "# Map class indices to names\n",
    "label_names = [\"normal\", \"offensive\", \"hatespeech\"]\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
    "    f1, roc_auc = evaluate(model, test_loader, device, label_names=label_names)\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | F1: {f1:.4f} | ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(\"=====================================\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
