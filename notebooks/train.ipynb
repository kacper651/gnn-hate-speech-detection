{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69b5b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from GNNs.GCNClassifier import GCNClassifier\n",
    "from GNNs.GRNClassifier import GRNClassifier\n",
    "\n",
    "from embeddings.word2vec import Word2VecEmbedding\n",
    "from embeddings.sbert import SBERTEmbedding\n",
    "\n",
    "from utils.graph_of_words import GraphOfWords\n",
    "from utils.graph_to_data import GraphToData\n",
    "from utils.dataset_wrapper import DatasetWrapper\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# TODO: come up with different method to load the dataset; as this one doesn't work\n",
    "dataset = load_dataset(\"Hate-speech-CNERG/hatexplain\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063ca4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 0\n",
      "Val size: 0\n",
      "Test size: 0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_majority_label(annotators):\n",
    "    if isinstance(annotators, list) and all(isinstance(ann, dict) for ann in annotators):\n",
    "        labels = [ann['label'] for ann in annotators if 'label' in ann]\n",
    "        most_common = Counter(labels).most_common(1)\n",
    "        return most_common[0][0] if most_common else None\n",
    "    return None\n",
    "\n",
    "# Process the dataset to extract texts and labels\n",
    "# def process_dataset(split):\n",
    "#     texts = []\n",
    "#     labels = []\n",
    "#     for example in dataset[split]:\n",
    "#         label = get_majority_label(example['annotators'])\n",
    "#         if label is not None:\n",
    "#             text = ' '.join(example['post_tokens'])\n",
    "#             texts.append(text)\n",
    "#             labels.append(label)\n",
    "#     return texts, labels\n",
    "\n",
    "def process_dataset(split):\n",
    "    texts, labels = [], []\n",
    "    for example in dataset[split]:\n",
    "        label = example.get('label')  # already an int 0, 1, or 2\n",
    "        if label is not None:\n",
    "            text = ' '.join(example['post_tokens'])\n",
    "            texts.append(text)\n",
    "            labels.append(label)\n",
    "    return texts, labels\n",
    "\n",
    "train_texts, train_labels = process_dataset('train')\n",
    "val_texts, val_labels = process_dataset('validation')\n",
    "test_texts, test_labels = process_dataset('test')\n",
    "\n",
    "print(f\"Train size: {len(train_texts)}\")\n",
    "print(f\"Val size: {len(val_texts)}\")\n",
    "print(f\"Test size: {len(test_texts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2598ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_embedder = Word2VecEmbedding(\"../models/google/GoogleNews-vectors-negative300.kv\", device=device)\n",
    "sbert_embedder = SBERTEmbedding(device=device)\n",
    "gow = GraphOfWords(embedding_model=w2v_embedder, window_size=2)\n",
    "text_to_graph = GraphToData(gow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10dbe164",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m val_dataset = DatasetWrapper(val_texts, val_labels, text_to_graph)\n\u001b[32m      5\u001b[39m test_dataset = DatasetWrapper(test_texts, test_labels, text_to_graph)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m train_loader = \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m val_loader = DataLoader(val_dataset, batch_size=\u001b[32m32\u001b[39m)\n\u001b[32m      9\u001b[39m test_loader = DataLoader(test_dataset, batch_size=\u001b[32m32\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\dev\\magisterka\\gnn-hate-speech-detection\\.venv\\Lib\\site-packages\\torch_geometric\\loader\\dataloader.py:87\u001b[39m, in \u001b[36mDataLoader.__init__\u001b[39m\u001b[34m(self, dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28mself\u001b[39m.follow_batch = follow_batch\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m.exclude_keys = exclude_keys\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCollater\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\dev\\magisterka\\gnn-hate-speech-detection\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:385\u001b[39m, in \u001b[36mDataLoader.__init__\u001b[39m\u001b[34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         sampler = \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    387\u001b[39m         sampler = SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\dev\\magisterka\\gnn-hate-speech-detection\\.venv\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:156\u001b[39m, in \u001b[36mRandomSampler.__init__\u001b[39m\u001b[34m(self, data_source, replacement, num_samples, generator)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    152\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.replacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    153\u001b[39m     )\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_samples <= \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    157\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.num_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    158\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_dataset = DatasetWrapper(train_texts, train_labels, text_to_graph)\n",
    "val_dataset = DatasetWrapper(val_texts, val_labels, text_to_graph)\n",
    "test_dataset = DatasetWrapper(test_texts, test_labels, text_to_graph)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
